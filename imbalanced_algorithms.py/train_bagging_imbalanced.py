import pandas as pd
import numpy as np
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score

#  Charger les nouveaux datasets dÃ©sÃ©quilibrÃ©s
X_train = pd.read_csv("../X_train_imbalanced.csv")
X_test = pd.read_csv("../X_test_imbalanced.csv")
y_train = pd.read_csv("../y_train_imbalanced.csv").values.ravel()
y_test = pd.read_csv("../y_test_imbalanced.csv").values.ravel()

print("ðŸš€ Training Bagging model on imbalanced data...")

#  EntraÃ®nement du modÃ¨le
model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)
model.fit(X_train, y_train)

#  PrÃ©dictions
y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)[:, 1]

# Ã‰valuation
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred, target_names=["Legitimate", "Polluter"])
roc_auc = roc_auc_score(y_test, y_proba)

tn, fp, fn, tp = conf_matrix.ravel()
tpr = tp / (tp + fn)
fpr = fp / (fp + tn)

#  Affichage des rÃ©sultats
print(f"âœ… Bagging (Imbalanced) Accuracy: {accuracy:.4f}")
print(f"âœ… True Positive Rate (TPR): {tpr:.4f}")
print(f"âœ… False Positive Rate (FPR): {fpr:.4f}")
print(f"âœ… F1-score for Polluters: {class_report.split()[-2]}")
print(f"âœ… ROC-AUC Score: {roc_auc:.4f}")

#  Sauvegarde des rÃ©sultats
results = pd.DataFrame({
    "Model": ["Bagging (Imbalanced)"],
    "Accuracy": [accuracy],
    "TPR": [tpr],
    "FPR": [fpr],
    "F1-score": [float(class_report.split()[-2])],
    "ROC-AUC": [roc_auc]
})
results.to_csv("../model_results_imbalanced.csv", index=False, mode='a', header=False)
